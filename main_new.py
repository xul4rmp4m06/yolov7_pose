#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
[YOLOv7-Pose æ•´åˆç‰ˆ v2 - ç„¡ Ultralytics ä¾è³´]
Multi-RTSP/Video real-time pose tracking:
  â€¢ æ¯å€‹ä¾†æºå„é–‹ä¸€å€‹ç·šç¨‹
  â€¢ æ¯å€‹ç·šç¨‹å„è‡ªè¼‰å…¥ YOLOv7-Pose æ¨¡å‹ (attempt_load)
  â€¢ æ¯å€‹ç·šç¨‹å„è‡ªè¼‰å…¥ä¸€å€‹ *è‡ªè¨‚çš„* SimpleCentroidTracker è¿½è¹¤å™¨
  â€¢ ä¿ç•™æ‰€æœ‰è·Œå€’åµæ¸¬ã€éœæ­¢åµæ¸¬ã€Discord åŠŸèƒ½
"""

import os, cv2, time, threading, numpy as np
import math
from datetime import datetime, timezone, timedelta
from collections import deque
import requests,json
from pathlib import Path

# --- æ–°å¢ï¼šYOLOv7-Pose ç›¸é—œ imports ---
import torch
from models.experimental import attempt_load
from utils.torch_utils import select_device
from utils.general import non_max_suppression_kpt
try:
    from utils.plots import plot_skeleton_kpts, plot_one_box
except ImportError:
    print("è­¦å‘Šï¼šç„¡æ³•å¾ utils.plots å°å…¥ plot_skeleton_kpts æˆ– plot_one_boxã€‚")
    # å¦‚æœå°å…¥å¤±æ•—ï¼Œæ‚¨å¯èƒ½éœ€è¦å¾ Wjdepp/yolov7-pose å€‰åº«ä¸­è¤‡è£½é€™äº›å‡½å¼

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0. ä½å»¶é² FFmpeg åƒæ•¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
os.environ["OPENCV_FFMPEG_CAPTURE_OPTIONS"] = (
    "rtsp_transport;udp|"
    "fflags;nobuffer|"
    "flags;low_delay|"
    "probesize;32|analyzeduration;0"
)
os.environ["OPENCV_FFMPEG_LOGLEVEL"] = "quiet"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. ä¾†æºæ¸…å–® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
USE_RTSP   = False
USE_VIDEOS = True

RTSP_URLS = [
    #r'rtsp://root:Asc%231432320@172.16.83.128:554/axis-media/media.amp?videocodec=h264&resolution=1920x1080&fps=10',
    #r'rtsp://root:Asc%231432320@172.16.83.171:554/axis-media/media.amp?videocodec=h264&resolution=1920x1080&fps=10',
    r'rtsp://admin:Asc%231432320@172.16.83.47:554/stream1',
    r'rtsp://root:Asc%231432320@172.16.83.42:554/axis-media/media.amp?videocodec=h264&resolution=1920x1080&fps=10',
]

VIDEO_FILES = [
    #r"C:\Users\User\SynologyDrive\py\aaa\test2-1.avi",
    #r"C:\Users\User\SynologyDrive\py\aaa\test2.avi",
    r"C:\Users\User\SynologyDrive\py\yoloV7_pose\1009-1.mp4",
]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. èƒŒæ™¯å–æµ (ä¿ç•™ä¸è®Š) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class LatestFrameRTSP:
    """
    èƒŒæ™¯ Thread æŒçºŒ read()ï¼Œåªå­˜æœ€æ–° frame
    get() éš¨æ™‚å›å‚³è¤‡è£½å¾Œçš„æœ€æ–° frameï¼ˆNone è¡¨ç¤ºå°šæœªæ‹¿åˆ°ï¼‰
    """
    def __init__(self, url: str, name: str):
        self.name = name
        self.cap  = cv2.VideoCapture(url, cv2.CAP_FFMPEG)
        if not self.cap.isOpened():
            raise RuntimeError(f"âŒ ç„¡æ³•é–‹å•Ÿ {url}")
        self.frame, self.lock = None, threading.Lock()
        self.running = True
        self.thread  = threading.Thread(target=self._reader, daemon=True)
        self.thread.start()
    def _reader(self):
        while self.running:
            ok, frm = self.cap.read()
            if ok:
                with self.lock:
                    self.frame = frm
            else:
                time.sleep(0.1)
        self.cap.release()
    def get(self):
        with self.lock:
            return None if self.frame is None else self.frame.copy()
    def stop(self):
        self.running = False
        self.thread.join()

class LatestFrameVideo:
    """
    å½±ç‰‡é€å¹€è®€å–ï¼›å›å‚³ None ä»£è¡¨å·²æ’­æ”¾çµæŸ
    """
    def __init__(self, path: str, name: str):
        self.name = name
        self.cap  = cv2.VideoCapture(path)
        if not self.cap.isOpened():
            raise RuntimeError(f"[{name}] ç„¡æ³•é–‹å•Ÿå½±ç‰‡ï¼š{path}")
        self.fps   = self.cap.get(cv2.CAP_PROP_FPS) or 0.0
        self.total = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)
    def get(self):
        ret, frame = self.cap.read()
        if not ret:
            return None
        return frame
    def release(self):
        try:
            self.cap.release()
        except Exception:
            pass

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Discord Webhooks (ä¿ç•™ä¸è®Š) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Alarm_bot = "https://discord.com/api/webhooks/1428747809250742343/7Y64YJRWq5SILy0eUmLVS5URYISgfE8ZnSBh8CMLLErv4qrTPegv5oyCMFWBT-k33ndD"
fail_like_bot = "https://discord.com/api/webhooks/1428748089719787550/0ib9j9yrokoadKq9LxRflU1DbW3dSuCY67MNQvCccJToTfTcCKxscrLEn_Vd4CDPXmOq"
img_bot = "https://discord.com/api/webhooks/1428748333488410624/tgJWFn_yYc0NdecNurixfJLktwFAU0cuXIDwYDBg2QdkC9JkS3YDagggDv_Vyx0lwj28"
systemlog_bot = "https://discord.com/api/webhooks/1428748579069235300/qm8x8uzbcWWkcOW4Vc9LTdcqf-rsQUQEZ17iDtLG82Fcy_-OSKvcGCkeTrvFp5__i6fa"


def Discord_message(bot,text: str,at=False):
    USER_ID = "447408102900498433"  # è¦@çš„é‚£å€‹äºº
    if at == False:
        payload = {"content": f"{text}","allowed_mentions": { "users": [USER_ID] }}
    else:
        payload = {"content": f"<@{USER_ID}> ï¼Œ{text}","allowed_mentions": { "users": [USER_ID] }}
    r = requests.post(bot, json=payload)
    print(r.status_code, r.text)

def Discord_send_image(bot,frame, text):
    USER_ID = "447408102900498433"  # è¦@çš„é‚£å€‹äºº
    at = f"<@{USER_ID}>" if USER_ID else ""
    content = f"{text}".strip()
    payload = {"content": content,"allowed_mentions": {"users": [USER_ID]} if USER_ID else {"users": []}}
    ok, buf = cv2.imencode(".png", frame)
    if not ok: raise RuntimeError("å½±åƒç·¨ç¢¼ PNG å¤±æ•—")
    files = {"file": ("frame.png", buf.tobytes(), "image/png")}
    data = {"payload_json": json.dumps(payload, ensure_ascii=False)}
    try:
        resp = requests.post(bot, data=data, files=files, timeout=20)
        return resp
    finally:
        return 

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. åƒæ•¸è¨­å®š (YOLOv7 + åŸæœ‰é‚è¼¯) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MODEL_DIR         = "yolov7-w6-pose.pt"     # *** ä¿®æ”¹ï¼šä½¿ç”¨ YOLOv7 æ¨¡å‹ ***
RAWIMGSZ          = 1920                      # *** ä¿®æ”¹ï¼šä½¿ç”¨ main.py çš„ 1920 å°ºå¯¸ ***
PLAYBACK_FPS      = 20.0                      # UI é¡¯ç¤ºç¯€æµ
DELAY_MS          = int(1000 / PLAYBACK_FPS)
MOVE_THRESH_PX    = 4                         # ç§»å‹• â‰¤3 px è¦–ç‚ºéœæ­¢
STATIC_TIME_S     = 240.0                     # éœæ­¢ â‰¥5 ç§’æ¨™ç´…
CONF_THR          = 0.25                      # å¯ä¿¡åº¦
IOU_THR           = 0.45                      # *** ä¿®æ”¹ï¼šä½¿ç”¨ main.py çš„ 0.45 ***
BOX_CONF_THR      = 0.50                      #åµæ¸¬æ¡†ä¿¡å¿ƒåº¦é–¾å€¼
KP_CONF_THR       = 0.5                       #0.8 é—œéµé»å¯ä¿¡åº¦
MIN_KP_OK         = 6
MAX_DET           = 800
SKELETON = [
    (15,13),(13,11),(16,14),(14,12),(11,12),
    (5,11),(6,12),(5,6),(5,7),(7,9),
    (6,8),(8,10),(1,2),(0,1),(0,2),
    (1,3),(2,4),(3,5),(4,6)
]

stop_event = threading.Event()

def _get_dist(p1, p2):
    return math.hypot(p1[0] - p2[0], p1[1] - p2[1])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. åµæ¸¬/æ¿¾æ³¢ ç›¸é—œé¡åˆ¥èˆ‡å‡½å¼ (ä¿ç•™ä¸è®Š) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class FallDetector:
    # ... (æ‚¨åŸæœ‰çš„ FallDetector é¡åˆ¥ç¨‹å¼ç¢¼ ... ä¿æŒä¸è®Š) ...
    # ... (ç‚ºäº†ç°¡æ½”ï¼Œæ­¤è™•çœç•¥ï¼Œè«‹è²¼ä¸Šæ‚¨åŸæœ‰çš„å®Œæ•´ FallDetector é¡åˆ¥) ...
    def __init__(
        self,
        # --- äº‹ä»¶å¼åµæ¸¬åƒæ•¸ (åµæ¸¬"éç¨‹") ---
        fps=10,
        drop_sigma_k=0.5,
        post_motion_eps=3.0,
        post_flat_vh=0.85,
        fall_cooldown_s=2.0,
        
        # --- ç‹€æ…‹æ©Ÿåƒæ•¸ (åµæ¸¬"ç‹€æ…‹") ---
        # å‚ç›´è·Œå€’/ç™±å€’çš„V/Hæ¯”ä¾‹é–€æª» (ç«™ç«‹æ™‚é€šå¸¸>2.5ï¼Œç™±åæ™‚<2.0)
        vertical_fall_vh_thresh=1.5, 
        # å‚ç›´è·Œå€’çš„è§’åº¦é–€æª»
        vertical_angle_deg_thresh = 20,
        # æ°´å¹³è·Œå€’çš„è§’åº¦é–€æª»
        angle_deg_thresh=55.0,
        # æ°´å¹³è·Œå€’çš„V/Hæ¯”ä¾‹é–€æª»
        horizontal_fall_vh_thresh=0.80,
        # è…¿éƒ¨å£“ç¸®æ¯”ä¾‹é–€æª» (è…¿é•·/èº«é«˜)
        leg_ratio_thresh=0.4,
        
        # é€£çºŒå¹€æ•¸ç¢ºèª
        frames_for_static_fall=60, 
        frames_to_alert=60,
        
        # --- é€šç”¨åƒæ•¸ ---
        conf_thr=0.5,
        debug=True
    ):
        # å„²å­˜æ‰€æœ‰åƒæ•¸
        self.fps = fps
        self.drop_sigma_k = drop_sigma_k
        self.post_motion_eps = post_motion_eps
        self.post_flat_vh = post_flat_vh
        self.fall_cooldown_s = fall_cooldown_s
        self.vertical_fall_vh_thresh = vertical_fall_vh_thresh
        self.vertical_angle_deg_thresh = vertical_angle_deg_thresh
        self.angle_deg_thresh = angle_deg_thresh
        self.horizontal_fall_vh_thresh = horizontal_fall_vh_thresh
        self.leg_ratio_thresh = leg_ratio_thresh
        self.frames_for_static_fall = frames_for_static_fall
        self.frames_to_alert = frames_to_alert
        self.conf_thr = conf_thr
        self.debug = debug

        self.track_history = {}

        # äº‹ä»¶å¼åµæ¸¬ç”¨çš„æ»‘å‹•è¦–çª—
        win = max(5, int(self.fps * 1.0))
        self._hip_y_hist = {}
        self._vh_hist = {}
        self._centroid_hist = {}
        self._last_fall_time = {}
        self._win = win
    
    def _update_fall_event(self, tid, pts, ts):
        """
        [äº‹ä»¶å¼åµæ¸¬] åµæ¸¬ 'ç«™â†’å€’' éç¨‹ (æ­¤å‡½å¼é‚è¼¯å¤§è‡´ä¿ç•™)
        å›å‚³ True è¡¨ç¤ºè§¸ç™¼ä¸€æ¬¡è·Œå€’äº‹ä»¶
        """
        P = np.asarray(pts, dtype=float)
        conf = P[:, 2]
        thr = self.conf_thr

        if tid not in self._hip_y_hist:
            self._hip_y_hist[tid] = deque(maxlen=self._win)
            self._vh_hist[tid] = deque(maxlen=self._win)
            self._centroid_hist[tid] = deque(maxlen=self._win)
            self._last_fall_time[tid] = -1.0

        if (conf[11] < thr) or (conf[12] < thr):
            return False

        hip_mid = (P[11, :2] + P[12, :2]) * 0.5
        valid = P[conf >= thr, :2]
        if valid.shape[0] < 6:
            return False

        xs, ys = valid[:, 0], valid[:, 1]
        H = max(1.0, xs.max() - xs.min())
        V = max(1.0, ys.max() - ys.min())
        vh_ratio = V / H
        centroid = valid.mean(axis=0)

        self._hip_y_hist[tid].append(float(hip_mid[1]))
        self._vh_hist[tid].append(float(vh_ratio))
        self._centroid_hist[tid].append(centroid)

        if len(self._hip_y_hist[tid]) < self._hip_y_hist[tid].maxlen:
            return False

        a = np.array(self._hip_y_hist[tid], dtype=float)
        N = len(a)
        first_half, second_half = a[:N//2], a[N//2:]
        med1, med2 = np.median(first_half), np.median(second_half)
        mad = np.median(np.abs(first_half - med1)) + 1e-6
        drop_sigma = (med2 - med1) / mad

        c = np.vstack(self._centroid_hist[tid])
        move_range = float(np.linalg.norm(c.max(axis=0) - c.min(axis=0), ord=2))
        is_static = (move_range <= self.post_motion_eps)
        is_flat = (np.median(self._vh_hist[tid]) <= self.post_flat_vh)
        
        head_hip_vert_norm = abs(P[0, 1] - hip_mid[1]) / V if conf[0] > thr else 1.0
        is_headhip_small = head_hip_vert_norm <= 0.3 # ä¸Šèº«å£“ç¸®

        is_drop_event = (drop_sigma >= self.drop_sigma_k)
        post_ok = is_static and (is_flat or is_headhip_small)

        if is_drop_event and post_ok:
            if (self._last_fall_time[tid] < 0) or (ts - self._last_fall_time[tid] >= self.fall_cooldown_s):
                self._last_fall_time[tid] = ts
                return True
        return False

    def _check_static_pose(self, pts):
        """
        [æ•´åˆå¾Œçš„éœæ…‹å§¿å‹¢åˆ†æ]
        åˆ¤æ–·å–®ä¸€å¹€çš„å§¿å‹¢æ˜¯å¦åƒè·Œå€’ï¼Œèƒ½åŒæ™‚è™•ç†æ°´å¹³å’Œå‚ç›´è·Œå€’ã€‚
        """
        P = np.asarray(pts, dtype=float)
        mask = P[:, 2] >= self.conf_thr
        
        # [ä¿®æ”¹] è‡³å°‘éœ€è¦6å€‹é»æ‰èƒ½é€²è¡Œå¯é çš„æ¯”ä¾‹è¨ˆç®—
        if mask.sum() < 6:
            return False

        try:
            # --- 1. è¨ˆç®—æ‰€æœ‰éœ€è¦çš„æŒ‡æ¨™ ---
            
            # 1a. èº«é«”ä¸»è»¸è§’åº¦
            p_sho_mid = (P[5, :2] + P[6, :2]) * 0.5
            p_hip_mid = (P[11, :2] + P[12, :2]) * 0.5
            vx, vy = p_hip_mid[0] - p_sho_mid[0], p_hip_mid[1] - p_sho_mid[1]
            n = math.hypot(vx, vy)
            angle_deg = 0.0
            if n > 1e-6:
                vy_n = np.clip(vy / n, -1.0, 1.0)
                angle_deg = math.degrees(math.acos(vy_n))
                if angle_deg > 90:
                    angle_deg = 180 - angle_deg
            
            # 1b. V/H æ¯”ä¾‹
            xy = P[mask, :2]
            xs, ys = xy[:, 0], xy[:, 1]
            H_spread = max(1.0, xs.max() - xs.min())
            V_spread = max(1.0, ys.max() - ys.min())
            vh_ratio = V_spread / H_spread
            
            # 1c. è…¿éƒ¨å£“ç¸®æ¯”ä¾‹
            p_ank_mid = (P[15, :2] + P[16, :2]) * 0.5
            p_nose = P[0, :2]
            leg_vertical_span = abs(p_hip_mid[1] - p_ank_mid[1])
            body_height_approx = abs(p_nose[1] - p_ank_mid[1])
            leg_compression_ratio = leg_vertical_span / body_height_approx if body_height_approx > 1e-6 else 1.0

            # --- 2. ç¶œåˆåˆ¤æ–· ---

            # [ä¿®æ”¹] æ¢ä»¶ä¸€ï¼šæ°´å¹³è·Œå€’ (è§’åº¦å¤§ ä¸” èº«é«”æ‰å¹³)
            cond_horizontal_fall = (angle_deg >= self.angle_deg_thresh and 
                                    vh_ratio <= self.horizontal_fall_vh_thresh)

            # [ä¿®æ”¹] æ¢ä»¶äºŒï¼šå‚ç›´è·Œå€’/ç™±å€’ (è§’åº¦å° ä½† èº«é«”è¢«å£“ç¸®)
            # èº«é«”è¢«å£“ç¸®å¯ä»¥ç”± V/Hæ¯”ä¾‹ æˆ– è…¿éƒ¨æ¯”ä¾‹ ä¾†åˆ¤æ–·
            cond_vertical_fall = (angle_deg < self.angle_deg_thresh and 
                                 (vh_ratio <= self.vertical_fall_vh_thresh or leg_compression_ratio <= self.leg_ratio_thresh))
            
            cond_vertical_angle_fall = (angle_deg >= self.vertical_angle_deg_thresh and 
                                        angle_deg <= self.vertical_angle_deg_thresh +3)
            
            fall_like = cond_horizontal_fall or cond_vertical_fall #or cond_vertical_angle_fall

            if self.debug and hasattr(self, '_is_debugging_tid') and self._is_debugging_tid:
                print(
                    f"    [Static Pose Check] Angle={angle_deg:.1f}Â°, V/H={vh_ratio:.2f}, LegRatio={leg_compression_ratio:.2f}\n"
                    f"    -> H_Fall(angle>{self.angle_deg_thresh}, vh<{self.horizontal_fall_vh_thresh})={cond_horizontal_fall} | "
                    f"V_Fall(angle<{self.angle_deg_thresh}, vh<{self.vertical_fall_vh_thresh} or leg<{self.leg_ratio_thresh})={cond_vertical_fall} | "
                    f"fall_like={fall_like}"
                )
            return fall_like

        except IndexError:
            return False

    def detect(self, pts, tid, frame_num):
        """ä¸»åµæ¸¬å‡½å¼ï¼Œçµåˆäº‹ä»¶å¼åµæ¸¬èˆ‡ç‹€æ…‹æ©Ÿã€‚"""
        tid = int(tid)
        P = np.asarray(pts, dtype=float)
        self._is_debugging_tid = True 

        if tid not in self.track_history:
            self.track_history[tid] = {
                'state': 'NORMAL', 
                'fallen_count': 0, 
                'last_hip_y': None,
                'last_frame_num': frame_num,
                'static_fall_pose_count': 0
            }
        
        history = self.track_history[tid]
        current_state = history['state']
        
        try:
            hip_mid_y = (P[11, 1] + P[12, 1]) * 0.5
        except IndexError:
            history['state'] = 'NORMAL'
            history['last_hip_y'] = None
            return False

        vertical_speed = 0.0
        if history['last_hip_y'] is not None:
            delta_frames = frame_num - history['last_frame_num']
            if delta_frames > 0:
                delta_y = hip_mid_y - history['last_hip_y']
                vertical_speed = delta_y / delta_frames
        
        history['last_hip_y'] = hip_mid_y
        history['last_frame_num'] = frame_num
        
        # --- [ä¿®æ”¹] ä½¿ç”¨æ•´åˆå¾Œçš„å§¿å‹¢åˆ¤æ–·å‡½å¼ ---
        is_in_fallen_pose = self._check_static_pose(P)
        
        # äº‹ä»¶å¼åµæ¸¬ä½œç‚ºè£œå……
        ts = frame_num / max(1e-6, float(self.fps))
        event_trigger = self._update_fall_event(tid, P, ts)

        # åªè¦äº‹ä»¶è§¸ç™¼ æˆ– é€£çºŒè™•æ–¼å€’åœ°å§¿å‹¢ï¼Œå°±èªç‚º "is_on_ground"
        is_on_ground = is_in_fallen_pose or event_trigger
        
        # --- ç‹€æ…‹æ©Ÿé‚è¼¯ (èˆ‡æ‚¨ä¸Šä¸€ç‰ˆç›¸åŒï¼Œéå¸¸ç©©å¥) ---
        new_state = current_state
        if current_state == 'NORMAL':
            if vertical_speed > 15.0: # ç°¡æ˜“çš„é€Ÿåº¦é–€æª»ï¼Œäº‹ä»¶å¼åµæ¸¬æ›´å¯é 
                new_state = 'FALLING'
                history['static_fall_pose_count'] = 0
            elif is_in_fallen_pose: # [ä¿®æ”¹] åªç”¨éœæ…‹å§¿å‹¢ä¾†è§¸ç™¼è¨ˆæ•¸
                history['static_fall_pose_count'] += 1
                if history['static_fall_pose_count'] >= self.frames_for_static_fall:
                    new_state = 'FALLEN'
                    history['fallen_count'] = 1
            else:
                history['static_fall_pose_count'] = 0

        elif current_state == 'FALLING':
            if is_in_fallen_pose:
                new_state = 'FALLEN'
                history['fallen_count'] = 1
            else:
                new_state = 'NORMAL'
        
        elif current_state == 'FALLEN':
            if is_in_fallen_pose:
                history['fallen_count'] += 1
                if history['fallen_count'] >= self.frames_to_alert:
                    new_state = 'ALERT'
            else:
                new_state = 'NORMAL'
                history['fallen_count'] = 0
        
        elif current_state == 'ALERT':
            if not is_in_fallen_pose:
                new_state = 'NORMAL'
                history['fallen_count'] = 0

        if new_state != 'NORMAL':
            history['static_fall_pose_count'] = 0
        history['state'] = new_state
        
        TZ = timezone(timedelta(hours=8), name="Asia/Taipei")
        now = datetime.now(TZ)
        if self.debug:
           print(
                f"[fall][tid={tid}][frame={frame_num}] [time={now.strftime('%Y/%m/%d %H:%M:%S')}] "
                f"state: {current_state:>7s} â†’ {new_state:>7s} | "
                f"alert_count={history['fallen_count']}/{self.frames_to_alert} | "
                f"static_pose_count={history['static_fall_pose_count']}/{self.frames_for_static_fall}"
                "\n-----------------------------------------------------------------------------------"
            )
        self._is_debugging_tid = False
        # [ä¿®æ”¹] äº‹ä»¶è§¸ç™¼æ™‚ï¼Œä¹Ÿç›´æ¥å›å‚³True (ç«‹å³è­¦å ±)
        if event_trigger:
            print(f"!!! EVENT TRIGGERED for tid={tid} !!!")
            return True
        return new_state == 'ALERT'
fall_detector = FallDetector()

def get_stable_center(P, conf_thr=0.6):
    # P: (17,3) [x,y,conf]
    ok = P[:,2] >= conf_thr
    # é«–ä¸­é»èˆ‡è‚©ä¸­é»ï¼ˆæœ‰ç¼ºå°±é€€è€Œæ±‚å…¶æ¬¡ï¼‰
    cands = []
    if ok[11] and ok[12]:
        hip_mid = ( (P[11,0] + P[12,0]) * 0.5, (P[11,1] + P[12,1]) * 0.5 )
        cands.append(("hip", hip_mid))
    if ok[5] and ok[6]:
        sho_mid = ( (P[5,0] + P[6,0]) * 0.5, (P[5,1] + P[6,1]) * 0.5 )
        cands.append(("sho", sho_mid))

    if not cands:
        # é€€åŒ–ï¼šç”¨æ‰€æœ‰é«˜ä¿¡å¿ƒé»çš„è³ªå¿ƒ
        if ok.any():
            xy = P[ok,:2]
            return float(xy[:,0].mean()), float(xy[:,1].mean())
        else:
            # å†é€€åŒ–ï¼šé¼»å­
            return float(P[0,0]), float(P[0,1])

    # åŠ æ¬Šå¹³å‡ï¼šé«– 0.7ã€è‚© 0.3
    w = {"hip":0.7, "sho":0.3}
    sx = sy = sw = 0.0
    for tag, (x,y) in cands:
        ww = w[tag]
        sx += ww*x; sy += ww*y; sw += ww
    return sx/sw, sy/sw

class OneEuro:
    # ... (æ‚¨åŸæœ‰çš„ OneEuro é¡åˆ¥ ... ä¿æŒä¸è®Š) ...
    # ç°¡åŒ–ç‰ˆ One Euro Filterï¼šç”¨åœ¨å–®ç¶­
    def __init__(self, freq=30.0, min_cutoff=1.0, beta=0.005, d_cutoff=1.0):
        self.freq = freq
        self.min_cutoff = min_cutoff
        self.beta = beta
        self.d_cutoff = d_cutoff
        self.x_prev = None
        self.dx_prev = 0.0
        self.t_prev = None

    def _alpha(self, cutoff):
        tau = 1.0 / (2*np.pi*cutoff)
        te  = 1.0 / max(1e-6, self.freq)
        return 1.0 / (1.0 + tau/te)

    def __call__(self, t, x):
        if self.t_prev is None:
            self.t_prev = t; self.x_prev = x
            return x
        # æ›´æ–°å¯¦éš›é »ç‡
        dt = max(1e-6, t - self.t_prev)
        self.freq = 1.0 / dt
        # å°æ•¸æ¿¾æ³¢
        dx = (x - self.x_prev) * self.freq
        a_d = self._alpha(self.d_cutoff)
        dx_hat = a_d*dx + (1-a_d)*self.dx_prev
        # ä¸»æ¿¾æ³¢ cutoff éš¨å‹•æ…‹èª¿æ•´
        cutoff = self.min_cutoff + self.beta*abs(dx_hat)
        a = self._alpha(cutoff)
        x_hat = a*x + (1-a)*self.x_prev
        # ç‹€æ…‹æ›´æ–°
        self.x_prev = x_hat
        self.dx_prev = dx_hat
        self.t_prev = t
        return x_hat

def estimate_jitter(P, cx, cy, conf_thr=0.6):
    ok = P[:,2] >= conf_thr
    if ok.sum() < 4:
        return 2.0  # ç¼ºé»æ™‚çµ¦å€‹ä¿å®ˆå€¼
    xy = P[ok,:2]
    # é—œéµé»ç›¸å°ä¸­å¿ƒçš„åŠå¾‘
    r = np.hypot(xy[:,0]-cx, xy[:,1]-cy)
    med = np.median(r)
    mad = np.median(np.abs(r - med)) + 1e-6
    # ç”¨ MAD ç•¶åšè©²å¹€çš„æŠ–å‹•åŸºæº–ï¼ˆä½ ä¹Ÿå¯ä»¥ä¹˜å€‹ä¿‚æ•¸ï¼‰
    return float(mad)

# --- æ–°å¢ï¼šè‡ªè¨‚çš„ç°¡æ˜“ä¸­å¿ƒé»è¿½è¹¤å™¨ ---
class SimpleCentroidTracker:
    def __init__(self, max_age=30, max_dist_px=100):
        self.next_tid = 0
        self.tracks = {}  # å„²å­˜: tid -> {'centroid':(cx,cy), 'kpts':(17,3), 'box':(4,), 'conf':f, 'age':0}
        self.max_age = max_age          # æ¶ˆå¤±Nå¹€å¾Œåˆªé™¤
        self.max_dist_px = max_dist_px  # å¹€é–“æœ€å¤§ç§»å‹•è·é›¢

    def _register(self, centroid, kpts, box, conf):
        tid = self.next_tid
        self.tracks[tid] = {
            'centroid': centroid,
            'kpts': kpts,
            'box': box,
            'conf': conf,
            'age': 0
        }
        self.next_tid += 1
        return tid

    def _deregister(self, tid):
        if tid in self.tracks:
            del self.tracks[tid]

    def update(self, det_results_v7_np):
        """
        ç”¨ YOLOv7 (N, 57) çš„ numpy é™£åˆ—ä¾†æ›´æ–°è¿½è¹¤å™¨
        å›å‚³: list of (tid, kpts_array, box_conf, box_xyxy)
        """
        
        # 1. ç‚ºç•¶å‰å¹€çš„æ‰€æœ‰åµæ¸¬çµæœè¨ˆç®—ä¸­å¿ƒé»
        new_detections = []
        for i in range(len(det_results_v7_np)):
            det_row = det_results_v7_np[i]
            kpts = det_row[6:].reshape(17, 3)
            box = det_row[:4]
            conf = det_row[4]
            
            # ä½¿ç”¨æ‚¨ v8 è…³æœ¬ä¸­çš„ 'get_stable_center'
            centroid = get_stable_center(kpts, conf_thr=KP_CONF_THR)
            new_detections.append({
                'centroid': centroid,
                'kpts': kpts,
                'box': box,
                'conf': conf
            })

        # å¦‚æœæ²’æœ‰å·²è¿½è¹¤ç›®æ¨™ï¼Œå…¨éƒ¨è¨»å†Šç‚ºæ–°çš„
        if len(self.tracks) == 0:
            for det in new_detections:
                self._register(det['centroid'], det['kpts'], det['box'], det['conf'])
            # (ç¬¬ä¸€æ¬¡ä¸å›å‚³ï¼Œç­‰å¾…ä¸‹ä¸€å¹€)
            return []

        # å»ºç«‹ç¾æœ‰TIDå’Œæ–°åµæ¸¬çš„ä¸­å¿ƒé»åˆ—è¡¨
        existing_tids = list(self.tracks.keys())
        existing_centroids = [t['centroid'] for t in self.tracks.values()]
        new_centroids = [d['centroid'] for d in new_detections]

        active_tracks_output = [] # æº–å‚™å›å‚³çš„åˆ—è¡¨

        if len(new_detections) > 0 and len(existing_tids) > 0:
            # 2. è¨ˆç®—è·é›¢çŸ©é™£ (èˆŠ track vs æ–° det)
            dist_matrix = np.zeros((len(existing_centroids), len(new_centroids)))
            for i in range(len(existing_centroids)):
                for j in range(len(new_centroids)):
                    dist_matrix[i, j] = _get_dist(existing_centroids[i], new_centroids[j])
            
            # 3. è²ªå©ªåŒ¹é… (Greedy Matching)
            # ç‚ºæ¯å€‹èˆŠ track æ‰¾åˆ°æœ€è¿‘çš„æ–° det
            matched_new_indices = set()
            unmatched_track_tids = set(existing_tids)

            # æ‰¾å‡ºæœ€ä½³åŒ¹é…å° (è·é›¢æœ€è¿‘çš„)
            matches = []
            for t_idx, tid in enumerate(existing_tids):
                if len(new_centroids) == 0: break # æ²’æœ‰å¯åŒ¹é…çš„äº†
                best_dist = np.inf
                best_d_idx = -1
                
                for d_idx in range(len(new_centroids)):
                    if d_idx in matched_new_indices:
                        continue # é€™å€‹ det å·²ç¶“è¢«åŒ¹é…éäº†
                    
                    d = dist_matrix[t_idx, d_idx]
                    if d < best_dist:
                        best_dist = d
                        best_d_idx = d_idx
                
                if best_dist < self.max_dist_px:
                    matches.append((tid, best_d_idx))
                    matched_new_indices.add(best_d_idx)
                    unmatched_track_tids.remove(tid)

            # 4. æ›´æ–°åŒ¹é…ä¸Šçš„ Track
            for tid, d_idx in matches:
                det = new_detections[d_idx]
                self.tracks[tid]['centroid'] = det['centroid']
                self.tracks[tid]['kpts'] = det['kpts']
                self.tracks[tid]['box'] = det['box']
                self.tracks[tid]['conf'] = det['conf']
                self.tracks[tid]['age'] = 0
                
                # åŠ å…¥åˆ°å›å‚³åˆ—è¡¨
                active_tracks_output.append((
                    tid, 
                    det['kpts'], 
                    det['conf'], 
                    det['box']
                ))

            # 5. è¨»å†ŠæœªåŒ¹é…ä¸Šçš„ Detections (æ–°ç›®æ¨™)
            for d_idx in range(len(new_detections)):
                if d_idx not in matched_new_indices:
                    det = new_detections[d_idx]
                    new_tid = self._register(det['centroid'], det['kpts'], det['box'], det['conf'])
                    # (æ–°è¨»å†Šçš„ç›®æ¨™ä¹Ÿç«‹åˆ»å›å‚³)
                    active_tracks_output.append((
                        new_tid, 
                        det['kpts'], 
                        det['conf'], 
                        det['box']
                    ))

            # 6. è™•ç†æœªåŒ¹é…ä¸Šçš„ Tracks (èˆŠç›®æ¨™)
            for tid in unmatched_track_tids:
                self.tracks[tid]['age'] += 1
                if self.tracks[tid]['age'] > self.max_age:
                    self._deregister(tid)
        
        elif len(new_detections) == 0:
             # æ²’æœ‰ä»»ä½•åµæ¸¬ï¼Œæ‰€æœ‰ track éƒ½ +1 age
             for tid in existing_tids:
                self.tracks[tid]['age'] += 1
                if self.tracks[tid]['age'] > self.max_age:
                    self._deregister(tid)
        
        return active_tracks_output


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. æ¯ç·šç¨‹ workerï¼š(ä¿®æ”¹ç‚º YOLOv7 + è‡ªè¨‚è¿½è¹¤å™¨) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def worker(stream, device="cuda:0"):
    """
    æ¯å€‹ç·šç¨‹éƒ½å„è‡ªè¼‰å…¥ä¸€é¡† YOLOv7 æ¨¡å‹ + SimpleCentroidTracker è¿½è¹¤å™¨
    """
    # ç·šç¨‹å°ˆå±¬ç‹€æ…‹
    STATIONARY = 0
    FALLEN = 0
    FALL_LIKE = 0
    ALERT_IDs = {}
    TZ = timezone(timedelta(hours=8), name="Asia/Taipei") #å°åŒ—æ™‚é–“
    center_filters = {}   # tid -> {"fx":OneEuro(...), "fy":OneEuro(...)}
    jitter_hist = {}      # tid -> deque æœ€è¿‘æŠ–å‹•ä¼°è¨ˆ
    
    # --- Discord Alert ç›¸é—œå‡½å¼ (ä¿ç•™ä¸è®Š) ---
    def next_alert(tid: str,alert_type: str) -> dict:
        # ... (èˆ‡æ‚¨ v8 è…³æœ¬ä¸­ç›¸åŒ, æ­¤è™•çœç•¥) ...
        now = datetime.now(TZ)
        slot = ALERT_IDs.get(tid)
        if slot is None: slot = {"seq_next": 0, "records": []}
        seq = slot["seq_next"]; slot["seq_next"] += 1
        rec = {"tid": tid,"seq": seq,"cam_name": window_name,"alert_type":alert_type,"time":  now.strftime("%Y/%m/%d %H:%M:%S"),"report": False}
        slot["records"].append(rec); ALERT_IDs[tid] = slot
        return rec
    
    # --- éæ¿¾å™¨ (ä¿ç•™ä¸è®Š) ---
    def pass_filters(box_conf: float, kp_conf: np.ndarray) -> bool:
        return (box_conf >= BOX_CONF_THR) and ((kp_conf >= KP_CONF_THR).sum() >= MIN_KP_OK)
    
    # --- ä¿®æ”¹ï¼šåˆå§‹åŒ– YOLOv7 æ¨¡å‹ ---
    print(f"[{stream.name}] æ­£åœ¨è¼‰å…¥ YOLOv7 æ¨¡å‹ {MODEL_DIR} åˆ° {device}...")
    device_obj = select_device(device)
    model = attempt_load(MODEL_DIR, map_location=device_obj)
    stride = int(model.stride.max())  # å° P6 æœƒæ˜¯ 64
    model.eval()
    half = (device_obj.type != 'cpu')
    if half:
        model.half()
    
    def align_to_stride(x: int, s: int) -> int:
        return (x + s - 1) // s * s
    
    raw_imgsz = RAWIMGSZ 
    imgsz = align_to_stride(raw_imgsz, stride)

    # --- ä¿®æ”¹ï¼šåˆå§‹åŒ– è‡ªè¨‚è¿½è¹¤å™¨ ---
    tracker = SimpleCentroidTracker(
        max_age=int(PLAYBACK_FPS * 1.5), # æ¶ˆå¤± 1.5 ç§’å¾Œåˆªé™¤
        max_dist_px=int(imgsz * 0.15)      # æœ€å¤§ç§»å‹•è·é›¢è¨­ç‚ºå½±åƒå°ºå¯¸çš„ 15%
    )
    
    prev_center, static_start_time = {}, {}
    window_name = str(stream.name)
    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
    cv2.resizeWindow(window_name, 800, 600)
    frame_count = 0
    
    while not stop_event.is_set():
        frame_count += 1 
        now = datetime.now(TZ)
        frame = stream.get()
        if frame is None:
            if isinstance(stream, LatestFrameVideo):
                break
            time.sleep(0.01)
            continue

        t0 = time.perf_counter()
        
        # --- æ ¸å¿ƒä¿®æ”¹ï¼šYOLOv7 æ¨è«–æµç¨‹ ---
        
        # 1. v7 Pre-processing
        img, ratio, (dw, dh) = letterbox(frame, imgsz, stride=stride)
        img_for_torch = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, HWC to CHW
        img_for_torch = np.ascontiguousarray(img_for_torch)
        
        img_torch = torch.from_numpy(img_for_torch).to(device_obj)
        img_torch = img_torch.half() if half else img_torch.float()
        img_torch /= 255.0
        if img_torch.ndimension() == 3:
            img_torch = img_torch.unsqueeze(0)

        # 2. v7 Inference
        with torch.no_grad():
            pred = model(img_torch)[0]

        # 3. v7 NMS
        det = non_max_suppression_kpt(pred, CONF_THR, IOU_THR, kpt_label=True)[0]
        
        proc_ms = (time.perf_counter() - t0) * 1000
        
        det_np_scaled = np.array([]) # æº–å‚™çµ¦ tracker çš„ numpy é™£åˆ—

        if det is not None and len(det):
            # 4. v7 åº§æ¨™é‚„åŸ (åœ¨å‚³çµ¦ tracker ä¹‹å‰)
            h, w, _ = frame.shape
            
            det[:, 0] = (det[:, 0] - dw) / ratio[0]  # x1
            det[:, 1] = (det[:, 1] - dh) / ratio[1]  # y1
            det[:, 2] = (det[:, 2] - dw) / ratio[0]  # x2
            det[:, 3] = (det[:, 3] - dh) / ratio[1]  # y2

            det[:, 6::3] = (det[:, 6::3] - dw) / ratio[0] # kpt x
            det[:, 7::3] = (det[:, 7::3] - dh) / ratio[1] # kpt y
            
            # å»ºç«‹ä¸€å€‹åŒ…å«æ‰€æœ‰ 'x' åº§æ¨™ç´¢å¼•çš„åˆ—è¡¨ (0, 2, 6, 9, 12, ...)
            # å‡è¨­æœ‰ 17 å€‹é—œéµé» (17*3=51)ï¼Œç¸½å…± 6+51=57 æ¬„
            all_x_indices = [0, 2] + list(range(6, 57, 3))
            # å»ºç«‹ä¸€å€‹åŒ…å«æ‰€æœ‰ 'y' åº§æ¨™ç´¢å¼•çš„åˆ—è¡¨ (1, 3, 7, 10, 13, ...)
            all_y_indices = [1, 3] + list(range(7, 57, 3))

            # ä½¿ç”¨é€™å€‹æœ‰æ•ˆçš„åˆ—è¡¨ä¾†é€²è¡Œç´¢å¼•å’Œ clamping
            det[:, all_x_indices] = det[:, all_x_indices].clamp(0, w)
            det[:, all_y_indices] = det[:, all_y_indices].clamp(0, h)
            
            det_np_scaled = det.cpu().numpy()
        
        # 5. æ›´æ–° è‡ªè¨‚è¿½è¹¤å™¨
        #    matched_results: list of (tid, kpts_array, box_conf, box_xyxy)
        matched_results = tracker.update(det_np_scaled)

        # 6. ä¿ç•™åŸæœ‰çš„ v8 è…³æœ¬é‚è¼¯ (è·Œå€’/éœæ­¢åµæ¸¬)
        if len(matched_results) > 0:
            for (tid, kpts_array, box_conf, (x1,y1,x2,y2)) in matched_results:
                
                pts = kpts_array # (17, 3) numpy array
                
                # åŸ·è¡Œ v8 è…³æœ¬çš„éæ¿¾å™¨
                kp_conf = pts[:, 2] # (17,)
                if not pass_filters(box_conf, kp_conf):
                    continue
                
                # --- (*** ä»¥ä¸‹æ˜¯å¾ v8 è…³æœ¬ä¸­å®Œæ•´è¤‡è£½çš„é‚è¼¯ ***) ---
                
                # â”€â”€ è¨ˆç®—ç§»å‹•è·é›¢ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                raw_cx, raw_cy = get_stable_center(pts, conf_thr=KP_CONF_THR)
                now_t = time.monotonic()
                flt = center_filters.get(tid)
                if flt is None:
                    flt = {
                        "fx": OneEuro(freq=PLAYBACK_FPS, min_cutoff=1.0, beta=0.01, d_cutoff=1.0),
                        "fy": OneEuro(freq=PLAYBACK_FPS, min_cutoff=1.0, beta=0.01, d_cutoff=1.0),
                    }
                    center_filters[tid] = flt
                cx = flt["fx"](now_t, raw_cx)
                cy = flt["fy"](now_t, raw_cy)

                jpx = estimate_jitter(pts, cx, cy, conf_thr=KP_CONF_THR)
                px, py  = prev_center.get(tid, (cx, cy))
                dist    = float(np.hypot(cx - px, cy - py))
                prev_center[tid] = (cx, cy)

                h = max(1.0, y2 - y1)
                thr_px = max(2.0, 2.5*jpx) * (h / 200.0)

                if dist <= thr_px:
                    if tid not in static_start_time:
                        static_start_time[tid] = time.monotonic()
                    static_sec = time.monotonic() - static_start_time[tid]
                else:
                    static_start_time.pop(tid, None)
                    static_sec = 0.0

                now_mono = time.monotonic()
                if dist <= MOVE_THRESH_PX:
                    if tid not in static_start_time:
                        static_start_time[tid] = now_mono
                    static_sec = now_mono - static_start_time[tid]
                else:
                    static_start_time.pop(tid, None)
                    static_sec = 0.0
                
                # â”€â”€ ç‹€æ…‹æ±ºç­– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                is_fallen = fall_detector.detect(pts, tid, frame_count)
                if static_sec >= STATIC_TIME_S:
                    STATIONARY += 1
                    next_alert(int(tid),"STATIONARY")
                    status, color = "STATIONARY",  (0,   0, 255)   # ç´… äººå“¡ç¦æ­¢ä¸å‹• è§¸ç™¼è­¦å ±
                elif is_fallen :
                    FALL_LIKE += 1
                    next_alert(int(tid),"FALL-LIKE")
                    status, color = "FALL-LIKE",  (0,   255, 255)   #é»ƒ äººå“¡ç–‘ä¼¼å€’åœ°
                elif is_fallen and static_sec >= STATIC_TIME_S:
                    FALLEN += 1
                    next_alert(int(tid),"FALLEN")
                    status, color = "FALLEN",  (0,   0, 255)   # ç´… äººå“¡ç–‘ä¼¼å€’åœ°ã€ç¦æ­¢ä¸å‹• è§¸ç™¼è­¦å ±
                else:
                    next_alert(int(tid),"STANDING")
                    status, color = "STANDING",(0, 255,   0)   # ç¶  äººå“¡æ­£å¸¸ç§»å‹•
                print(f"CAM:{window_name} STATIONARY:{STATIONARY} FALL_LIKE:{FALL_LIKE} FALLEN:{FALLEN}")
                
                # â”€â”€ ç¹ªè£½æ¡† / éª¨æ¶ / é—œéµé» â”€â”€â”€â”€â”€â”€â”€
                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
                cv2.rectangle(frame,(x1,y1),(x2,y2), color, 2)
                
                if 'plot_skeleton_kpts' in globals():
                    plot_skeleton_kpts(frame, pts.reshape(-1), 3) # å‚³å…¥ 1D array (51,)
                
                cv2.putText(frame, f"ID:{int(tid)} {status} {static_sec:.1f}s",
                            (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 8) #æ–‡å­—é»‘åº•
                cv2.putText(frame, f"ID:{int(tid)} {status} {static_sec:.1f}s",
                            (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2) #æ–‡å­—

        # â”€â”€ ç•«æ¨è«–è€—æ™‚ & é¡¯ç¤º â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        cv2.putText(frame, f"{window_name}  {proc_ms:.1f} ms frame_count:{frame_count} {now.strftime('%Y/%m/%d %H:%M:%S')}",
                    (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,0), 8) #æ–‡å­—é»‘åº•
        cv2.putText(frame, f"{window_name}  {proc_ms:.1f} ms frame_count:{frame_count} {now.strftime('%Y/%m/%d %H:%M:%S')}",
                    (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,255), 2)#æ–‡å­—

        cv2.imshow(window_name, frame)
        if cv2.waitKey(DELAY_MS) & 0xFF == 27:   # ESC
            stop_event.set()
            break
    
    cv2.destroyWindow(window_name)
    if hasattr(stream, "stop"): stream.stop()
    if hasattr(stream, "release"): stream.release()
    print(f"ğŸ›‘ {window_name} çµæŸ")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 6. å»ºç«‹æ‰€æœ‰ä¸²æµã€ä¾æ•¸é‡è‡ªå‹•é–‹ç·šç¨‹ (ä¿ç•™ä¸è®Š) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_streams():
    streams = []
    idx = 1
    if USE_RTSP:
        for i, url in enumerate(RTSP_URLS):
            streams.append(LatestFrameRTSP(url, f"CAM{i+1}"))
            idx += 1
    if USE_VIDEOS:
        for j, p in enumerate(VIDEO_FILES):
            name = f"VID{j+1}-{Path(p).stem}"
            streams.append(LatestFrameVideo(p, name))
            idx += 1
    if not streams:
        raise RuntimeError("æ²’æœ‰ä»»ä½•ä¾†æºå¯ç”¨ï¼Œè«‹è¨­å®š RTSP_URLS æˆ– VIDEO_FILESã€‚")
    return streams

def main():
    # å»ºç«‹ä¸²æµ
    streams = build_streams()

    # è‡ªå‹•åµæ¸¬ GPUï¼Œè¼ªè©¢åˆ†é… device
    try:
        import torch
        n_gpu = torch.cuda.device_count()
    except Exception:
        n_gpu = 0

    def device_for(k):
        if n_gpu >= 1:
            return f"cuda:{k % n_gpu}"
        else:
            return "cpu"

    threads = []
    for k, stream in enumerate(streams):
        dev = device_for(k)
        t = threading.Thread(target=worker, args=(stream, dev), daemon=True)
        threads.append(t)

    # èµ·ç·šç¨‹
    for t in threads: t.start()

    # ç­‰å¾…å…¨éƒ¨çµæŸ
    try:
        while True:
            if stop_event.is_set():
                break
            time.sleep(1.0)
    except KeyboardInterrupt:
        print("\n[Main] åµæ¸¬åˆ° Ctrl+Cï¼Œæ­£åœ¨è¦æ±‚æ‰€æœ‰ç·šç¨‹åœæ­¢...")
        stop_event.set()
    
    for t in threads: 
        t.join()

    cv2.destroyAllWindows()
    print("âœ… ç¨‹å¼å·²å®Œå…¨çµæŸ")

# --- æ–°å¢ï¼šLetterbox è¼”åŠ©å‡½å¼ (ä¾†è‡ª main.py) ---
def letterbox(img, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True, stride=32):
    shape = img.shape[:2]  # current shape [height, width]
    if isinstance(new_shape, int):
        new_shape = (new_shape, new_shape)

    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])
    if not scaleup:
        r = min(r, 1.0)

    ratio = r, r
    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))
    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]
    if auto:
        dw, dh = np.mod(dw, stride), np.mod(dh, stride)
    elif scaleFill:
        dw, dh = 0.0, 0.0
        new_unpad = (new_shape[1], new_shape[0])
        ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]

    dw /= 2
    dh /= 2

    if shape[::-1] != new_unpad:
        img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)
    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))
    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))
    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)
    return img, ratio, (dw, dh)

if __name__ == "__main__":
    main()